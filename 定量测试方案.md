# 定量测试方案：ADD(5cm/5°)准确率评估

## 概述

本文档说明如何使用ArUco标记获取GT位姿，并评估追踪算法在ADD(5cm/5°)标准下的准确率。

## 1. 准备工作

### 1.1 打印ArUco标记

1. 使用OpenCV生成ArUco标记（推荐使用DICT_6X6_250字典，ID=0）：
```python
import cv2
import numpy as np

# 创建ArUco字典
dictionary = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_6X6_250)

# 生成标记图像（300x300像素，边距20像素）
marker_image = np.ones((300, 300), dtype=np.uint8) * 255
marker = cv2.aruco.generateImageMarker(dictionary, 0, 300, marker_image, 1)

# 保存标记
cv2.imwrite("aruco_marker_0.png", marker_image)
```

2. 打印标记（推荐尺寸：5cm x 5cm，即marker_size=0.05m）

### 1.2 安装依赖

确保已安装以下Python包：
```bash
pip install opencv-contrib-python  # 包含ArUco支持
```

### 1.3 准备测试环境

1. 将ArUco标记固定在物体上（魔方）
   - 标记中心应与物体中心对齐（或记录偏移量）
   - 标记平面应与物体一个面平行

2. 确保RealSense相机可以同时看到：
   - IR图像中的物体
   - ArUco标记（在IR图像中清晰可见）

## 2. 获取GT位姿

### 2.1 使用GT位姿捕获工具

运行以下命令启动GT位姿捕获工具：

```bash
conda run -n deepac python src_open/tools/capture_gt_poses.py \
    --cfg src_open/configs/live/realsense_ir_tracking.yaml \
    --marker_size 0.05 \
    --marker_id 0 \
    --save_images
```

### 2.2 操作说明

1. **对齐标记**：将ArUco标记放在相机视野中，确保标记清晰可见
2. **捕获帧**：按 `SPACE` 键捕获当前帧的GT位姿
3. **保存**：按 `s` 键保存所有捕获的GT位姿并退出
4. **退出**：按 `ESC` 或 `q` 键退出（不保存）

### 2.3 输出文件

GT位姿将保存到：
- `{save_dir}/gt_poses.json`：JSON格式的GT位姿文件
- `{save_dir}/frame_XXXXXX.png`：捕获的图像（如果启用了`--save_images`）

### 2.4 GT位姿文件格式

```json
{
  "0": {
    "R": [[r11, r12, r13], [r21, r22, r23], [r31, r32, r33]],
    "t": [tx, ty, tz]
  },
  "1": {
    "R": [...],
    "t": [...]
  },
  ...
}
```

其中：
- `R`：旋转矩阵（3x3），从物体坐标系到相机坐标系
- `t`：平移向量（3x1），物体中心在相机坐标系中的位置（米）

## 3. 运行追踪算法

运行追踪算法并保存预测位姿：

```bash
conda run -n deepac python src_open/tools/live_tracking_realsense.py \
    --cfg src_open/configs/live/realsense_ir_tracking.yaml
```

预测位姿将保存到：
- `{save_dir}/pose.txt`：每行12个数字（R的9个元素 + t的3个元素）

**注意**：确保追踪时使用与GT捕获时相同的相机配置和物体位置。

## 4. 评估ADD(5cm/5°)准确率

### 4.1 运行评估脚本

```bash
conda run -n deepac python src_open/tools/evaluate_add_accuracy.py \
    --pred_poses workspace/live_cube_ir_innovative/pose.txt \
    --gt_poses workspace/live_cube_ir_innovative/gt_poses.json \
    --add_threshold 0.05 \
    --rotation_threshold 5.0 \
    --geometry_unit 0.001 \
    --output workspace/live_cube_ir_innovative/evaluation_results.json
```

### 4.2 参数说明

- `--pred_poses`：预测位姿文件路径（pose.txt）
- `--gt_poses`：GT位姿文件路径（gt_poses.json）
- `--add_threshold`：ADD阈值（米），默认0.05m（5cm）
- `--rotation_threshold`：旋转阈值（度），默认5.0度
- `--geometry_unit`：几何单位（米），用于转换预测位姿的单位，默认0.001m（1mm）
- `--output`：输出结果文件路径（可选）

### 4.3 评估指标

评估脚本将计算以下指标：

1. **ADD(5cm)准确率**：ADD误差 ≤ 5cm的帧占比
2. **旋转(5°)准确率**：旋转误差 ≤ 5°的帧占比
3. **组合准确率（ADD(5cm/5°)）**：同时满足ADD ≤ 5cm和旋转 ≤ 5°的帧占比
4. **平均误差**：
   - 平均ADD误差（毫米）
   - 平均旋转误差（度）
   - 平均平移误差（毫米）
5. **中位数误差**：
   - 中位数ADD误差（毫米）
   - 中位数旋转误差（度）
   - 中位数平移误差（毫米）

### 4.4 输出示例

```
============================================================
ADD(5cm/5°) Accuracy Evaluation Results
============================================================
Total frames: 193
Valid frames: 193

Accuracy Metrics:
  ADD(5cm) accuracy:     85.49%
  Rotation(5°) accuracy: 92.23%
  Combined ADD(5cm/5°):  82.38%

Average Errors:
  ADD error:            3.45 mm
  Rotation error:       2.18 deg
  Translation error:    2.67 mm

Median Errors:
  ADD error:            2.89 mm
  Rotation error:       1.95 deg
  Translation error:    2.34 mm
============================================================
```

## 5. RealSense接口说明

### 5.1 RealSense是否提供GT位姿？

**答案：不直接提供。**

RealSense相机本身不提供物体的GT位姿。RealSense提供：
- **IR图像**：用于追踪
- **深度图**：可用于辅助追踪（当前未使用）
- **相机内参**：用于位姿估计

### 5.2 获取GT位姿的方法

1. **ArUco标记**（推荐，本方案采用）
   - 优点：精确、易于实现、实时
   - 缺点：需要在物体上粘贴标记

2. **手动标注**
   - 优点：不需要标记
   - 缺点：耗时、不实时

3. **其他追踪系统**
   - 使用M3T等成熟的追踪系统作为GT
   - 需要额外的硬件和软件

### 5.3 ArUco标记的优势

- **高精度**：使用solvePnP算法，精度可达毫米级
- **实时性**：可以实时检测和估计位姿
- **鲁棒性**：在IR图像中也能良好工作
- **易于使用**：OpenCV内置支持

## 6. 完整测试流程

### 步骤1：准备ArUco标记
```bash
# 生成并打印ArUco标记（见1.1节）
```

### 步骤2：捕获GT位姿
```bash
conda run -n deepac python src_open/tools/capture_gt_poses.py \
    --cfg src_open/configs/live/realsense_ir_tracking.yaml \
    --marker_size 0.05 \
    --marker_id 0 \
    --save_images
```

### 步骤3：运行追踪算法
```bash
conda run -n deepac python src_open/tools/live_tracking_realsense.py \
    --cfg src_open/configs/live/realsense_ir_tracking.yaml
```

### 步骤4：评估准确率
```bash
conda run -n deepac python src_open/tools/evaluate_add_accuracy.py \
    --pred_poses workspace/live_cube_ir_innovative/pose.txt \
    --gt_poses workspace/live_cube_ir_innovative/gt_poses.json \
    --output workspace/live_cube_ir_innovative/evaluation_results.json
```

### 步骤5：查看性能分析结果
```bash
# 性能分析结果保存在：
cat workspace/live_cube_ir_innovative/performance_profile.txt
```

## 7. 注意事项

1. **标记大小**：确保`--marker_size`参数与实际打印的标记大小一致（单位：米）
2. **标记ID**：确保`--marker_id`与使用的标记ID一致
3. **帧同步**：GT捕获和追踪运行时的帧索引需要对应
4. **相机配置**：GT捕获和追踪使用相同的相机配置（分辨率、内参等）
5. **物体位置**：GT捕获和追踪时物体位置应尽量一致

## 8. 故障排除

### 问题1：ArUco标记检测不到
- **原因**：标记太小、光照不足、标记模糊
- **解决**：增大标记尺寸、改善光照、确保标记清晰

### 问题2：GT位姿不准确
- **原因**：标记大小参数错误、相机内参不准确
- **解决**：校准标记大小、重新校准相机内参

### 问题3：帧数不匹配
- **原因**：GT捕获和追踪的帧数不一致
- **解决**：确保使用相同的帧率，或手动对齐帧索引

## 9. 性能优化建议

1. **使用快速边缘可信度模式**：在配置文件中设置`use_fast_edge_confidence: true`
2. **启用性能分析**：查看各模块耗时，识别瓶颈
3. **调整模板数量**：减少`template_top_k`以提高速度（可能降低精度）

## 10. 参考资源

- [ArUco标记生成器](https://chev.me/arucogen/)
- [OpenCV ArUco文档](https://docs.opencv.org/4.x/d5/dae/tutorial_aruco_detection.html)
- [ADD评估指标说明](https://github.com/thodan/bop_toolkit)








